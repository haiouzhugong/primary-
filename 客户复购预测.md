<h1>Table of Contents<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#读取数据" data-toc-modified-id="读取数据-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>读取数据</a></span></li><li><span><a href="#数据分析" data-toc-modified-id="数据分析-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>数据分析</a></span></li><li><span><a href="#特征工程" data-toc-modified-id="特征工程-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>特征工程</a></span><ul class="toc-item"><li><span><a href="#特征空值处理" data-toc-modified-id="特征空值处理-3.1"><span class="toc-item-num">3.1&nbsp;&nbsp;</span>特征空值处理</a></span></li><li><span><a href="#特征可视化" data-toc-modified-id="特征可视化-3.2"><span class="toc-item-num">3.2&nbsp;&nbsp;</span>特征可视化</a></span></li></ul></li><li><span><a href="#模型构建" data-toc-modified-id="模型构建-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>模型构建</a></span><ul class="toc-item"><li><span><a href="#逻辑回归" data-toc-modified-id="逻辑回归-4.1"><span class="toc-item-num">4.1&nbsp;&nbsp;</span>逻辑回归</a></span></li><li><span><a href="#K邻近" data-toc-modified-id="K邻近-4.2"><span class="toc-item-num">4.2&nbsp;&nbsp;</span>K邻近</a></span></li><li><span><a href="#决策树" data-toc-modified-id="决策树-4.3"><span class="toc-item-num">4.3&nbsp;&nbsp;</span>决策树</a></span></li><li><span><a href="#随机森林" data-toc-modified-id="随机森林-4.4"><span class="toc-item-num">4.4&nbsp;&nbsp;</span>随机森林</a></span></li><li><span><a href="#梯度提示回归树" data-toc-modified-id="梯度提示回归树-4.5"><span class="toc-item-num">4.5&nbsp;&nbsp;</span>梯度提示回归树</a></span></li><li><span><a href="#多层感知机" data-toc-modified-id="多层感知机-4.6"><span class="toc-item-num">4.6&nbsp;&nbsp;</span>多层感知机</a></span></li><li><span><a href="#原始数据缩放" data-toc-modified-id="原始数据缩放-4.7"><span class="toc-item-num">4.7&nbsp;&nbsp;</span>原始数据缩放</a></span></li><li><span><a href="#特征构建" data-toc-modified-id="特征构建-4.8"><span class="toc-item-num">4.8&nbsp;&nbsp;</span>特征构建</a></span></li></ul></li><li><span><a href="#模型预测" data-toc-modified-id="模型预测-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>模型预测</a></span></li></ul></div>


```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
plt.rcParams["font.sans-serif"] = "SimHei" #解决中文乱码问题
import seaborn as sns
import time
import random
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn import model_selection
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz
import graphviz
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
```

# 读取数据
----
- 读取数据<br>
- 数据预处理


```python
df_train = pd.read_csv(r'D:\\数据源\\test1\\data_format1\\train_format1.csv')
df_test = pd.read_csv(r'D:\\数据源\\test1\\data_format1\\test_format1.csv')
user_info = pd.read_csv(r'D:\\数据源\\test1\\data_format1\\user_info_format1.csv')
user_log = pd.read_csv(r'D:\\数据源\\test1\\data_format1\\user_log_format1.csv')
```


```python
df_test.shape,df_train.shape
```




    ((261477, 3), (260864, 3))




```python
user_info.shape,user_log.shape
```




    ((424170, 3), (54925330, 7))




```python
user_info.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 424170 entries, 0 to 424169
    Data columns (total 3 columns):
     #   Column     Non-Null Count   Dtype  
    ---  ------     --------------   -----  
     0   user_id    424170 non-null  int64  
     1   age_range  421953 non-null  float64
     2   gender     417734 non-null  float64
    dtypes: float64(2), int64(1)
    memory usage: 9.7 MB
    


```python
user_info.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>age_range</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>376517</td>
      <td>6.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>234512</td>
      <td>5.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>344532</td>
      <td>5.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>186135</td>
      <td>5.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>30230</td>
      <td>5.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>272389</td>
      <td>6.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>281071</td>
      <td>4.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>139859</td>
      <td>7.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>198411</td>
      <td>5.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>67037</td>
      <td>4.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>



空值处理<br>
age_range：用户年龄范围。<18岁为1；[18,24]为2； [25,29]为3； [30,34]为4；[35,39]为5；[40,49]为6； > = 50时为7和8; 0和NULL表示未知<br>
gender：用户性别。0表示女性，1表示男性，2和NULL表示未知


```python
# 用np.nan替换空值（not a number 表示不是一个数字，np.nan是一个float类型的数据所有涉及nan的操作，返回的都是nan）
user_info['age_range'].replace(0.0,np.nan,inplace=True) 
user_info['gender'].replace(2.0,np.nan,inplace=True)
user_info.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 424170 entries, 0 to 424169
    Data columns (total 3 columns):
     #   Column     Non-Null Count   Dtype  
    ---  ------     --------------   -----  
     0   user_id    424170 non-null  int64  
     1   age_range  329039 non-null  float64
     2   gender     407308 non-null  float64
    dtypes: float64(2), int64(1)
    memory usage: 9.7 MB
    


```python
# 把nan值替换成-1方便可视化
user_info['age_range'].replace(np.nan,-1,inplace=True)
user_info['gender'].replace(np.nan,-1,inplace=True)
```


```python
fig = plt.figure(figsize = (10, 6))
x = np.array(["NULL","<18","18-24","25-29","30-34","35-39","40-49",">=50"])
#<18岁为1；[18,24]为2； [25,29]为3； [30,34]为4；[35,39]为5；[40,49]为6； > = 50时为7和8
y = np.array([user_info[user_info['age_range'] == -1]['age_range'].count(),
             user_info[user_info['age_range'] == 1]['age_range'].count(),
             user_info[user_info['age_range'] == 2]['age_range'].count(),
             user_info[user_info['age_range'] == 3]['age_range'].count(),
             user_info[user_info['age_range'] == 4]['age_range'].count(),
             user_info[user_info['age_range'] == 5]['age_range'].count(),
             user_info[user_info['age_range'] == 6]['age_range'].count(),
             user_info[user_info['age_range'] == 7]['age_range'].count() + user_info[user_info['age_range'] == 8]['age_range'].count()])
plt.bar(x,y,label='人数')
plt.legend()
plt.title('用户年龄分布')
```




    Text(0.5, 1.0, '用户年龄分布')




    
![png](output_11_1.png)
    



```python
sns.countplot(x='gender',order = [-1,0,1],data = user_info)
plt.title('用户性别分布')
```




    Text(0.5, 1.0, '用户性别分布')




    
![png](output_12_1.png)
    



```python
sns.countplot(x = 'age_range', order = [-1,1,2,3,4,5,6,7,8], hue = 'gender', data = user_info)
plt.title('用户性别年龄分布')
#年龄空值为-1；<18岁为1；[18,24]为2； [25,29]为3； [30,34]为4；[35,39]为5；[40,49]为6； > = 50时为7和8
```




    Text(0.5, 1.0, '用户性别年龄分布')




    
![png](output_13_1.png)
    


- 上图可以发现性别空值较少，年龄空值交多
- 用户年龄分布主要范围在18-34岁之间
- 缺失值后续特征构建时处理


```python
user_info['age_range'].replace(-1,np.nan,inplace=True)
user_info['gender'].replace(-1,np.nan,inplace=True)
sns.countplot(x = 'age_range', order = [-1,1,2,3,4,5,6,7,8],hue= 'gender',data = user_info)
plt.title('用户性别年龄分布')
```




    Text(0.5, 1.0, '用户性别年龄分布')




    
![png](output_15_1.png)
    



```python
user_log.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>item_id</th>
      <th>cat_id</th>
      <th>seller_id</th>
      <th>brand_id</th>
      <th>time_stamp</th>
      <th>action_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>328862</td>
      <td>323294</td>
      <td>833</td>
      <td>2882</td>
      <td>2661.0</td>
      <td>829</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>328862</td>
      <td>844400</td>
      <td>1271</td>
      <td>2882</td>
      <td>2661.0</td>
      <td>829</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>328862</td>
      <td>575153</td>
      <td>1271</td>
      <td>2882</td>
      <td>2661.0</td>
      <td>829</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>328862</td>
      <td>996875</td>
      <td>1271</td>
      <td>2882</td>
      <td>2661.0</td>
      <td>829</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>328862</td>
      <td>1086186</td>
      <td>1271</td>
      <td>1253</td>
      <td>1049.0</td>
      <td>829</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
user_log.isnull().sum(axis=0)
```




    user_id            0
    item_id            0
    cat_id             0
    seller_id          0
    brand_id       91015
    time_stamp         0
    action_type        0
    dtype: int64




```python
user_log.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 54925330 entries, 0 to 54925329
    Data columns (total 7 columns):
     #   Column       Dtype  
    ---  ------       -----  
     0   user_id      int64  
     1   item_id      int64  
     2   cat_id       int64  
     3   seller_id    int64  
     4   brand_id     float64
     5   time_stamp   int64  
     6   action_type  int64  
    dtypes: float64(1), int64(6)
    memory usage: 2.9 GB
    

空值不多

# 数据分析


```python
user_log['time_stamp'].hist(bins = 9)
```




    <AxesSubplot:>




    
![png](output_21_1.png)
    


618和双十一购买的东西最多


```python
sns.countplot(x = 'action_type', order = [0,1,2,3],data = user_log)
```




    <AxesSubplot:xlabel='action_type', ylabel='count'>




    
![png](output_23_1.png)
    


绝大多数都是单击，加入购物车的动作很少，比购买和收藏的动作还要少

# 特征工程
----
需要根据user_id，和merchant_id（seller_id）,从用户画像表以及用户日志表中提取特征，填写到df_train这个数据框中，从而训练评估模型 需要建立的特征如下：<br>
- 用户的年龄(age_range)
- 用户的性别(gender)
- 某用户在该商家日志的总条数(total_logs)
- 用户浏览的商品的数目，就是浏览了多少个商品(unique_item_ids)
- 浏览的商品的种类的数目，就是浏览了多少种商品(categories)
- 用户浏览的天数(browse_days)
- 用户单击的次数(one_clicks)
- 用户添加购物车的次数(shopping_carts)
- 用户购买的次数(purchase_times)
- 用户收藏的次数(favourite_times)


```python
df_train = pd.merge(df_train,user_info,on="user_id",how="left") # 用户年龄和性别特征添加
```


```python
# 用户在该商家日志的总条数
total_logs_temp = user_log.groupby(["user_id", "seller_id"]).count().reset_index()[["user_id","seller_id","item_id"]]
total_logs_temp.rename(columns={"seller_id":"merchant_id","item_id":"total_logs"},inplace=True)
df_train = pd.merge(df_train,total_logs_temp,on=["user_id","merchant_id"],how="left")
total_logs_temp.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>merchant_id</th>
      <th>total_logs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>471</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>739</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>925</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1019</td>
      <td>14</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1156</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 用户浏览的商品的数目
unique_item_ids_temp = user_log.groupby([user_log["user_id"],user_log["seller_id"],user_log["item_id"]]).count().reset_index()[["user_id","seller_id","item_id"]]
unique_item_ids_temp1 = unique_item_ids_temp.groupby([unique_item_ids_temp["user_id"],unique_item_ids_temp["seller_id"]]).count().reset_index()
unique_item_ids_temp1.rename(columns={"seller_id":"merchant_id","item_id":"unique_item_ids"},inplace=True)
unique_item_ids_temp1.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>merchant_id</th>
      <th>unique_item_ids</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>471</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>739</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>925</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1019</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1156</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1</td>
      <td>2245</td>
      <td>4</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>4026</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1</td>
      <td>4177</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1</td>
      <td>4335</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2</td>
      <td>420</td>
      <td>15</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_train = pd.merge(df_train,unique_item_ids_temp1,on=["user_id","merchant_id"],how="left")
```


```python
# 浏览的商品的种类的数目
categories_temp = user_log.groupby(["user_id", "seller_id", "cat_id"]).count().reset_index()[["user_id","seller_id","cat_id"]]
categories_temp1 = categories_temp.groupby([categories_temp["user_id"],categories_temp["seller_id"]]).count().reset_index()
categories_temp1.rename(columns={"seller_id":"merchant_id","cat_id":"categories"},inplace=True)
df_train = pd.merge(df_train,categories_temp1,on=["user_id","merchant_id"],how="left")
categories_temp1.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>merchant_id</th>
      <th>categories</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>471</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>739</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>925</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1019</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1156</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1</td>
      <td>2245</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>4026</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1</td>
      <td>4177</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1</td>
      <td>4335</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2</td>
      <td>420</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 用户浏览的天数
browse_days_temp = user_log.groupby([user_log["user_id"],user_log["seller_id"],user_log["time_stamp"]]).count().reset_index()[["user_id","seller_id","time_stamp"]]
browse_days_temp1 = browse_days_temp.groupby([browse_days_temp["user_id"],browse_days_temp["seller_id"]]).count().reset_index()
browse_days_temp1.rename(columns={"seller_id":"merchant_id","time_stamp":"browse_days"},inplace=True)
df_train = pd.merge(df_train,browse_days_temp1,on=["user_id","merchant_id"],how="left")
browse_days_temp1.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>merchant_id</th>
      <th>browse_days</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>471</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>739</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>925</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1019</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1156</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1</td>
      <td>2245</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>4026</td>
      <td>2</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1</td>
      <td>4177</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1</td>
      <td>4335</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2</td>
      <td>420</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 用户单击的次数、用户添加购物车的次数、用户购买的次数、用户收藏的次数
one_clicks_temp = user_log.groupby([user_log["user_id"],user_log["seller_id"],user_log["action_type"]]).count().reset_index()[["user_id","seller_id","action_type","item_id"]]
one_clicks_temp.rename(columns={"seller_id":"merchant_id","item_id":"times"},inplace=True)
one_clicks_temp["one_clicks"] = one_clicks_temp["action_type"] == 0
one_clicks_temp["one_clicks"] = one_clicks_temp["one_clicks"] * one_clicks_temp["times"]
one_clicks_temp["shopping_carts"] = one_clicks_temp["action_type"] == 1
one_clicks_temp["shopping_carts"] = one_clicks_temp["shopping_carts"] * one_clicks_temp["times"]
one_clicks_temp["purchase_times"] = one_clicks_temp["action_type"] == 2
one_clicks_temp["purchase_times"] = one_clicks_temp["purchase_times"] * one_clicks_temp["times"]
one_clicks_temp["favourite_times"] = one_clicks_temp["action_type"] == 3
one_clicks_temp["favourite_times"] = one_clicks_temp["favourite_times"] * one_clicks_temp["times"]
four_features = one_clicks_temp.groupby([one_clicks_temp["user_id"],one_clicks_temp["merchant_id"]]).sum().reset_index()
four_features = four_features.drop(["action_type","times"], axis=1)
df_train = pd.merge(df_train,four_features,on=["user_id","merchant_id"],how="left")
```


```python
df_train.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>merchant_id</th>
      <th>label</th>
      <th>age_range</th>
      <th>gender</th>
      <th>total_logs</th>
      <th>unique_item_ids</th>
      <th>categories</th>
      <th>browse_days</th>
      <th>one_clicks</th>
      <th>shopping_carts</th>
      <th>purchase_times</th>
      <th>favourite_times</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>34176</td>
      <td>3906</td>
      <td>0</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>39</td>
      <td>20</td>
      <td>6</td>
      <td>9</td>
      <td>36</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>34176</td>
      <td>121</td>
      <td>0</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>14</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>13</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>34176</td>
      <td>4356</td>
      <td>1</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>18</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>12</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>34176</td>
      <td>2217</td>
      <td>0</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>230784</td>
      <td>4818</td>
      <td>0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>8</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>7</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>362112</td>
      <td>2618</td>
      <td>0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>34944</td>
      <td>2051</td>
      <td>0</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>231552</td>
      <td>3828</td>
      <td>1</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>83</td>
      <td>48</td>
      <td>15</td>
      <td>3</td>
      <td>78</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>231552</td>
      <td>2124</td>
      <td>0</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>7</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>6</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>232320</td>
      <td>1168</td>
      <td>0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



## 特征空值处理


```python
df_train.isnull().sum(axis=0)
```




    user_id                0
    merchant_id            0
    label                  0
    age_range          57062
    gender             10694
    total_logs             0
    unique_item_ids        0
    categories             0
    browse_days            0
    one_clicks             0
    shopping_carts         0
    purchase_times         0
    favourite_times        0
    dtype: int64




```python
# 缺失值向前填充
df_train = df_train.fillna(method='ffill')
df_train.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 260864 entries, 0 to 260863
    Data columns (total 13 columns):
     #   Column           Non-Null Count   Dtype  
    ---  ------           --------------   -----  
     0   user_id          260864 non-null  int64  
     1   merchant_id      260864 non-null  int64  
     2   label            260864 non-null  int64  
     3   age_range        260864 non-null  float64
     4   gender           260864 non-null  float64
     5   total_logs       260864 non-null  int64  
     6   unique_item_ids  260864 non-null  int64  
     7   categories       260864 non-null  int64  
     8   browse_days      260864 non-null  int64  
     9   one_clicks       260864 non-null  int64  
     10  shopping_carts   260864 non-null  int64  
     11  purchase_times   260864 non-null  int64  
     12  favourite_times  260864 non-null  int64  
    dtypes: float64(2), int64(11)
    memory usage: 27.9 MB
    

## 特征可视化


```python
plt.style.use('ggplot')
sns.countplot(x = 'age_range', order = [1,2,3,4,5,6,7,8],hue= 'gender',data = df_train)
plt.title('训练集用户性别年龄分布')
```




    Text(0.5, 1.0, '训练集用户性别年龄分布')




    
![png](output_38_1.png)
    



```python
colnm = df_train.columns.tolist()
print(colnm)
plt.figure(figsize = (5, 4))
color = sns.color_palette()

df_train[colnm[5]].hist(range=[0,80],bins = 80,color = color[1])
plt.xlabel(colnm[5],fontsize = 12)
plt.ylabel('用户数')
```

    ['user_id', 'merchant_id', 'label', 'age_range', 'gender', 'total_logs', 'unique_item_ids', 'categories', 'browse_days', 'one_clicks', 'shopping_carts', 'purchase_times', 'favourite_times']
    




    Text(0, 0.5, '用户数')




    
![png](output_39_2.png)
    



```python
df_train[colnm[6]].hist(range=[0,40],bins = 40,color = color[1])
plt.xlabel(colnm[6],fontsize = 12)
plt.ylabel('用户数')
```




    Text(0, 0.5, '用户数')




    
![png](output_40_1.png)
    



```python
df_train[colnm[7]].hist(range=[0,10],bins = 10,color = color[1])
plt.xlabel(colnm[7],fontsize = 12)
plt.ylabel('用户数')
```




    Text(0, 0.5, '用户数')




    
![png](output_41_1.png)
    



```python
df_train[colnm[8]].hist(range=[0,10],bins = 10,color = color[1])
plt.xlabel(colnm[8],fontsize = 12)
plt.ylabel('用户数')
```




    Text(0, 0.5, '用户数')




    
![png](output_42_1.png)
    



```python
df_train[colnm[9]].hist(range=[0,50],bins = 50,color = color[1])
plt.xlabel(colnm[9],fontsize = 12)
plt.ylabel('用户单击次数统计')
```




    Text(0, 0.5, '用户单击次数统计')




    
![png](output_43_1.png)
    



```python
df_train[colnm[10]].hist(range=[0,3],bins = 3,color = color[1])
plt.xlabel(colnm[10],fontsize = 12)
plt.ylabel('用户数')
```




    Text(0, 0.5, '用户数')




    
![png](output_44_1.png)
    



```python
df_train[colnm[11]].hist(range=[0,6],bins = 7,color = color[1])
plt.xlabel(colnm[11],fontsize = 12)
plt.ylabel("用户数")
```




    Text(0, 0.5, '用户数')




    
![png](output_45_1.png)
    



```python
df_train[colnm[12]].hist(range=[0,6],bins = 6,color = color[1])
plt.xlabel(colnm[12],fontsize = 12)
plt.ylabel("用户数")
```




    Text(0, 0.5, '用户数')




    
![png](output_46_1.png)
    



```python
# 相关性
sns.set_style("dark")

plt.figure(figsize = (14,10))
colnm = df_train.columns.tolist()[2:13]
mcorr = df_train[colnm].corr()
# np.zero_like的意思就是生成一个和你所给数组a相同shape的全0数组。
mask = np.zeros_like(mcorr, dtype=np.bool)
# np.triu_indices_from()返回方阵的上三角矩阵的索引
mask[np.triu_indices_from(mask)] = True
cmap = sns.diverging_palette(220, 10, as_cmap=True)
g = sns.heatmap(mcorr, mask=mask, cmap=cmap, square=True, annot=True,fmt='0.2f')
```


    
![png](output_47_0.png)
    


# 模型构建

## 逻辑回归


```python
Y = df_train['label']
X = df_train.drop(['user_id','merchant_id','label'],axis = 1)
# 划分训练集
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.25,random_state = 10)
Logit = LogisticRegression(solver='liblinear')
Logit.fit(X_train, y_train)
Predict = Logit.predict(X_test)
Predict_proba = Logit.predict_proba(X_test)
print(Predict[0:20])
print(Predict_proba[:])
# 一般的准确率验证方法
Score = accuracy_score(y_test, Predict)
Score

```

    [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
    [[0.79596456 0.20403544]
     [0.95828116 0.04171884]
     [0.95192758 0.04807242]
     ...
     [0.9405193  0.0594807 ]
     [0.95677734 0.04322266]
     [0.93242875 0.06757125]]
    




    0.9382053483807654



## K邻近


```python
# 模型实例化，并将邻居个数设为3 
reg = KNeighborsRegressor(n_neighbors=1000)
# 利用训练数据和训练目标值来拟合模型 
reg.fit(X_train, y_train)
print("Test set R^2: {:.2f}".format(reg.score(X_test, y_test)))
#这一算法对于有很多特 征（几百或更多）的数据集往往效果不好，对于大多数特征的大多数取值都为 0 的数据集 （所谓的稀疏数据集）来说，这一算法的效果尤其不好
```

    Test set R^2: 0.01
    

## 决策树


```python
tree = DecisionTreeClassifier(max_depth=4,random_state=0) 
tree.fit(X_train, y_train)
Predict_proba = tree.predict_proba(X_test)
export_graphviz(tree, out_file="tree.dot", class_names=["0","1"], feature_names=X.columns.tolist(), impurity=False, filled=True)
# 可以利用 tree 模块的 export_graphviz 函数来将树可视化。这个函数会生成一 个 .dot 格式的文件，这是一种用于保存图形的文本文件格式。
# 设置为结点添加颜色 的选项，颜色表示每个结点中的多数类别，同时传入类别名称和特征名称，这样可以对 树正确标记
with open("tree.dot") as f: 
    dot_graph = f.read() 
graphviz.Source(dot_graph)
plt.barh(X.columns.tolist(),height=0.5,width=tree.feature_importances_,align="center")
```




    <BarContainer object of 10 artists>




    
![png](output_54_1.png)
    


## 随机森林


```python
forest = RandomForestClassifier(n_estimators=10, random_state=2) 
forest.fit(X_train, y_train)
Predict_proba = forest.predict_proba(X_test)
plt.barh(X.columns.tolist(),height=0.5,width=forest.feature_importances_,align="center")
```




    <BarContainer object of 10 artists>




    
![png](output_56_1.png)
    


## 梯度提示回归树


```python
gbrt = GradientBoostingClassifier(random_state=0) 
gbrt.fit(X_train, y_train)
Predict_proba = gbrt.predict_proba(X_test)
plt.barh(X.columns.tolist(),height=0.5,width=gbrt.feature_importances_,align="center")
```




    <BarContainer object of 10 artists>




    
![png](output_58_1.png)
    


## 多层感知机


```python
mlp = MLPClassifier(solver='lbfgs', activation='relu',alpha=0.1,random_state=0,hidden_layer_sizes=[10,10]).fit(X_train, y_train)
Predict = mlp.predict(X_test)
Predict_proba = mlp.predict_proba(X_test)
Score = accuracy_score(y_test, Predict)
plt.figure(figsize=(20, 10))
plt.imshow(mlp.coefs_[0], interpolation='none', cmap='viridis')
plt.yticks(range(10), X.columns.tolist()) 
plt.xlabel("Columns in weight matrix") 
plt.ylabel("Input feature") 
plt.colorbar()
```

    d:\python\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    
    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
      self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)
    




    <matplotlib.colorbar.Colorbar at 0x23ec5dae288>



    d:\python\lib\site-packages\matplotlib\backends\backend_agg.py:238: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    d:\python\lib\site-packages\matplotlib\backends\backend_agg.py:201: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)
    


    
![png](output_60_3.png)
    


## 原始数据缩放


```python
scaler = StandardScaler()
X_train = X_train[X_train.columns.tolist()].astype(float)
X_test = X_test[X_test.columns.tolist()].astype(float)
scaler.fit(X_train)
# 变换数据
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

## 特征构建


```python
df_test = pd.merge(df_test,user_info,on="user_id",how="left")
df_test = pd.merge(df_test,total_logs_temp,on=["user_id","merchant_id"],how="left")
df_test = pd.merge(df_test,unique_item_ids_temp1,on=["user_id","merchant_id"],how="left")
df_test = pd.merge(df_test,categories_temp1,on=["user_id","merchant_id"],how="left")
df_test = pd.merge(df_test,browse_days_temp1,on=["user_id","merchant_id"],how="left")
df_test = pd.merge(df_test,four_features,on=["user_id","merchant_id"],how="left")
df_test = df_test.fillna(method='bfill')# 向后填充
df_test = df_test.fillna(method='ffill')# 向前填充
df_test.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>merchant_id</th>
      <th>prob</th>
      <th>age_range</th>
      <th>gender</th>
      <th>total_logs</th>
      <th>unique_item_ids</th>
      <th>categories</th>
      <th>browse_days</th>
      <th>one_clicks</th>
      <th>shopping_carts</th>
      <th>purchase_times</th>
      <th>favourite_times</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>163968</td>
      <td>4605</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>360576</td>
      <td>1581</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>10</td>
      <td>9</td>
      <td>4</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>98688</td>
      <td>1964</td>
      <td>NaN</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>6</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>98688</td>
      <td>3645</td>
      <td>NaN</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>11</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>10</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>295296</td>
      <td>3361</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>50</td>
      <td>8</td>
      <td>4</td>
      <td>5</td>
      <td>47</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>33408</td>
      <td>98</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>11</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>9</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>230016</td>
      <td>1742</td>
      <td>NaN</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>13</td>
      <td>6</td>
      <td>1</td>
      <td>1</td>
      <td>11</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>164736</td>
      <td>598</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>164736</td>
      <td>1963</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>164736</td>
      <td>2634</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>7</td>
      <td>4</td>
      <td>3</td>
      <td>1</td>
      <td>6</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



# 模型预测


```python
X1 = df_test.drop(['user_id','merchant_id','prob'],axis = 1)
X1.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age_range</th>
      <th>gender</th>
      <th>total_logs</th>
      <th>unique_item_ids</th>
      <th>categories</th>
      <th>browse_days</th>
      <th>one_clicks</th>
      <th>shopping_carts</th>
      <th>purchase_times</th>
      <th>favourite_times</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.0</td>
      <td>0.0</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>0.0</td>
      <td>10</td>
      <td>9</td>
      <td>4</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6.0</td>
      <td>0.0</td>
      <td>6</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6.0</td>
      <td>0.0</td>
      <td>11</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>10</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>1.0</td>
      <td>50</td>
      <td>8</td>
      <td>4</td>
      <td>5</td>
      <td>47</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>




```python
Predict_proba = Logit.predict_proba(X1)
df_test["Logit_prob"] = Predict_proba[:,1]
Predict_proba = tree.predict_proba(X1)
df_test["Tree_prob"] = Predict_proba[:,1]
Predict_proba = forest.predict_proba(X1)
df_test["Forest_prob"] = Predict_proba[:,1]
Predict_proba = gbrt.predict_proba(X1)
df_test["Gbrt_prob"] = Predict_proba[:,1]
Predict_proba = mlp.predict_proba(X1)
df_test["mlp_prob"] = Predict_proba[:,1]
```


```python
df_test.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>merchant_id</th>
      <th>prob</th>
      <th>age_range</th>
      <th>gender</th>
      <th>total_logs</th>
      <th>unique_item_ids</th>
      <th>categories</th>
      <th>browse_days</th>
      <th>one_clicks</th>
      <th>shopping_carts</th>
      <th>purchase_times</th>
      <th>favourite_times</th>
      <th>Logit_prob</th>
      <th>Tree_prob</th>
      <th>Forest_prob</th>
      <th>Gbrt_prob</th>
      <th>mlp_prob</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>163968</td>
      <td>4605</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.045679</td>
      <td>0.041629</td>
      <td>0.032803</td>
      <td>0.036615</td>
      <td>0.042487</td>
    </tr>
    <tr>
      <th>1</th>
      <td>360576</td>
      <td>1581</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>10</td>
      <td>9</td>
      <td>4</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>0.121231</td>
      <td>0.102396</td>
      <td>0.000000</td>
      <td>0.109463</td>
      <td>0.099004</td>
    </tr>
    <tr>
      <th>2</th>
      <td>98688</td>
      <td>1964</td>
      <td>NaN</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>6</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.054257</td>
      <td>0.041629</td>
      <td>0.010370</td>
      <td>0.043843</td>
      <td>0.053075</td>
    </tr>
    <tr>
      <th>3</th>
      <td>98688</td>
      <td>3645</td>
      <td>NaN</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>11</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>10</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.053202</td>
      <td>0.041629</td>
      <td>0.000000</td>
      <td>0.043843</td>
      <td>0.052823</td>
    </tr>
    <tr>
      <th>4</th>
      <td>295296</td>
      <td>3361</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>50</td>
      <td>8</td>
      <td>4</td>
      <td>5</td>
      <td>47</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0.058432</td>
      <td>0.068542</td>
      <td>0.100000</td>
      <td>0.076745</td>
      <td>0.068552</td>
    </tr>
    <tr>
      <th>5</th>
      <td>33408</td>
      <td>98</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>11</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>9</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0.053664</td>
      <td>0.047680</td>
      <td>0.000000</td>
      <td>0.045435</td>
      <td>0.050930</td>
    </tr>
    <tr>
      <th>6</th>
      <td>230016</td>
      <td>1742</td>
      <td>NaN</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>13</td>
      <td>6</td>
      <td>1</td>
      <td>1</td>
      <td>11</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0.058423</td>
      <td>0.089106</td>
      <td>0.000000</td>
      <td>0.074029</td>
      <td>0.069322</td>
    </tr>
    <tr>
      <th>7</th>
      <td>164736</td>
      <td>598</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.043567</td>
      <td>0.041629</td>
      <td>0.039958</td>
      <td>0.037901</td>
      <td>0.051072</td>
    </tr>
    <tr>
      <th>8</th>
      <td>164736</td>
      <td>1963</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.043889</td>
      <td>0.047680</td>
      <td>0.046536</td>
      <td>0.043581</td>
      <td>0.047655</td>
    </tr>
    <tr>
      <th>9</th>
      <td>164736</td>
      <td>2634</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>7</td>
      <td>4</td>
      <td>3</td>
      <td>1</td>
      <td>6</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.050510</td>
      <td>0.068542</td>
      <td>0.000000</td>
      <td>0.053930</td>
      <td>0.058570</td>
    </tr>
  </tbody>
</table>
</div>




```python
choose = ["user_id","merchant_id","mlp_prob"]
res = df_test[choose]
res.rename(columns={"mlp_prob":"prob"},inplace=True)
print(res.head(10))
res.to_csv(path_or_buf = r"D:\\数据源\\test1\\data_format1\\prediction.csv",index = False)
```

    d:\python\lib\site-packages\pandas\core\frame.py:4308: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      errors=errors,
    

       user_id  merchant_id      prob
    0   163968         4605  0.042487
    1   360576         1581  0.099004
    2    98688         1964  0.053075
    3    98688         3645  0.052823
    4   295296         3361  0.068552
    5    33408           98  0.050930
    6   230016         1742  0.069322
    7   164736          598  0.051072
    8   164736         1963  0.047655
    9   164736         2634  0.058570
    


```python

```
